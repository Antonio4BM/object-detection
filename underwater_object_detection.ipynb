{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddecf85-ea0c-4dbe-8ef2-bcda3df4287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15212b5-c3bc-4096-9109-678b5b0cf0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import intersection_over_union\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b528a1c8-a1db-4b55-a62e-ffc6d6fa70f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.4.2), please consider upgrading to the latest version (1.0.0)"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"slavkoprytula/aquarium-data-cots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6983a9b-20b4-4442-bac9-326adafb23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(path):\n",
    "    filenames = []\n",
    "    for file in path.iterdir():\n",
    "        filenames.append(file.stem)\n",
    "    return pd.DataFrame({\n",
    "        \"filename\": filenames\n",
    "    })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7661d4-5543-4753-bba0-73c38573ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = build_dataframe(Path(f\"{path}/aquarium_pretrain/train/labels\"))\n",
    "test_df = build_dataframe(Path(f\"{path}/aquarium_pretrain/test/labels\"))\n",
    "valid_df = build_dataframe(Path(f\"{path}/aquarium_pretrain/valid/labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1d6640c-e004-4f18-91c6-0865aeea1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderWaterDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, path, split_size, boxes, classes, transform=None):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.S = split_size\n",
    "        self.B = boxes\n",
    "        self.C = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.loc[index,'filename']\n",
    "        boxes = []\n",
    "        with open(f\"{self.path}/labels/{filename}.txt\") as f:\n",
    "            for line in f.readlines():\n",
    "                label, x, y, width, height = line.split()\n",
    "                boxes.append([int(label), float(x), float(y), float(width), float(height)])\n",
    "\n",
    "        label_matrix = torch.zeros((self.S, self.S, 5 + self.C))\n",
    "\n",
    "        image = Image.open(f\"{self.path}/images/{filename}.jpg\")\n",
    "\n",
    "        for box in boxes:\n",
    "            label, x, y, width, height = box\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "            width_cell, height_cell = width * self.S, height * self.S\n",
    "\n",
    "            if label_matrix[i, j, self.C] == 0:\n",
    "                label_matrix[i, j, self.C] = 1\n",
    "                box_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell, width_cell, height_cell]\n",
    "                )\n",
    "                label_matrix[i, j, self.C+1:self.C+5] = box_coordinates\n",
    "                label_matrix[i, j, label] = 1\n",
    "\n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a625424f-ef73-4ca2-986c-f9d683e142a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UnderWaterDataset(train_df, f\"{path}/aquarium_pretrain/train\", 7, 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "717411e2-7d78-4c37-8bf2-96411cdebd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iterator = iter(train_dataset)\n",
    "element = next(dataset_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b77e205-528f-48c6-aeca-126cb1843301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (kernel size, out channels, strides, padding)\n",
    "\n",
    "architecture_config = [\n",
    "    (7, 64, 2, 3),\n",
    "    \"M\",\n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n",
    "    (1, 512, 1, 0),\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3a2a304-b28b-43c9-94e0-28d979660b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51396365-a107-4fc9-910c-793d80549f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloV1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, **kwargs):\n",
    "        super(YoloV1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.architecture = architecture_config\n",
    "\n",
    "        self.darknet = self._create_conv_layers(self.architecture)\n",
    "        self.fcs = self._create_fcs(**kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x)\n",
    "        x = self.fcs(torch.flatten(x, start_dim=1))\n",
    "        return x\n",
    "\n",
    "    def _create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == tuple:\n",
    "                layers += [CNNBlock(in_channels, out_channels=x[1], kernel_size=x[0], stride=x[2], padding=x[3])]\n",
    "                in_channels = x[1]\n",
    "            elif type(x) == str:\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            elif type(x) == list:\n",
    "                conv_1 = x[0]\n",
    "                conv_2 = x[1]\n",
    "                n = x[2]\n",
    "                for _ in range(n):\n",
    "                    layers += [CNNBlock(in_channels, out_channels=conv_1[1], kernel_size=conv_1[0], stride=conv_1[2], padding=conv_1[3])]\n",
    "                    layers += [CNNBlock(conv_1[1], out_channels=conv_2[1], kernel_size=conv_2[0], stride=conv_2[2], padding=conv_2[3])]\n",
    "                    in_channels = conv_2[1]\n",
    "                    \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def _create_fcs(self, split_size, num_boxes, num_classes):\n",
    "\n",
    "        S, B, C = split_size, num_boxes, num_classes\n",
    "        return nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * S * S, 496),\n",
    "            nn.Dropout(0.0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(496, S * S * (B * 5 + C))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ef47e43-7c09-4c36-8ca0-315eecb1dd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1470])\n"
     ]
    }
   ],
   "source": [
    "model = YoloV1(split_size=7, num_boxes=2, num_classes=20)\n",
    "x = torch.randn((2, 3, 448, 448))\n",
    "logits = model(x)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf65cdd-78ae-4c72-8899-ef6b90342a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, S, B, C):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "        self.B = B\n",
    "        self.S = S\n",
    "        self.C = C\n",
    "\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = predictions.view(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        iou_b1 = intersection_over_union(predictions[:, :, :, 21:25], targets[:, :, :, 21:25])\n",
    "        iou_b2 = intersection_over_union(predictions[:, :, :, 26:30], targets[:, :, :, 21:25])\n",
    "\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
    "        iou_maxes, best_box = torch.max(ious, dim=0)\n",
    "        exists_box = targets[:, :, :, 20].unsqueeze(3) # identity object i\n",
    "\n",
    "\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                ((1 - best_box) * predictions[:, :, :, 21:25]) +\n",
    "                best_box * predictions[:, :, :, 26:30]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        box_targets = exists_box * targets[:, 21:25]\n",
    "\n",
    "        box_predictions[:, :, :, 2:4] =  (\n",
    "            torch.sign(box_predictions[:, :, :, 2:4]) * \n",
    "            torch.sqrt(torch.abs(box_predictions[:, :, :, 2:4]) + 1e-6)\n",
    "        )\n",
    "\n",
    "        box_targets[: , :, :, 2:4] = torch.sqrt(box_targets[:, :, :, 2:4])\n",
    "\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2),\n",
    "            torch.flatten(box_targets, end_dim=-2)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        pred_box = (\n",
    "            ((1 - best_box) * predictions[:, :, :, 20:21]) +\n",
    "            (best_box * predictions[:, :, :, 25:26])\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box)\n",
    "            torch.flatten(exists_box * targets[:, :, :, 20:21])\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1-exists_box) * predictions[:, :, :, 20:21], start_dim=1)\n",
    "            torch.flatten((1-exists_box) * targets[:, :, :, 20:21], start_dim=1)\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1-exists_box) * predictions[:, :, :, 25:26], start_dim=1)\n",
    "            torch.flatten((1-exists_box) * targets[:, :, :, 20:21], start_dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[:, :, :, :20], end_dim=-2)\n",
    "            torch.flatten(exists_box * targets[:, :, :, :20], end_dim=-2)\n",
    "        )\n",
    "\n",
    "\n",
    "        general_loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + object_loss\n",
    "            + self.lambda_noobj * no_object_loss\n",
    "            + class_loss\n",
    "        )\n",
    "\n",
    "        return general_loss        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
